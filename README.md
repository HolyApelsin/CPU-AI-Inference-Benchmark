# CPU-AI-Inference-Benchmark (WIP)
Mini training / learning project: CPU AI Inference Benchmark

## About
Comparison of MobileNetV2 model inference performance on **CPU** in different environments: **PyTorch**, **ONNX RunTime** and other (maybe). Application of INT8 quantization.

## Results
(soon)

## Roadmap
1. Write results.
2. Improve the project in terms of code and comments.

## Tools
- VS Code (WSL)
